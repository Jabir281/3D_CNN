{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6637846b",
   "metadata": {},
   "source": [
    "# Lung Cancer Detection with 3D CNN (LUNA16 Dataset - Subset 0)\n",
    "\n",
    "This notebook demonstrates the steps to build and train a 3D CNN for lung nodule detection using **Subset 0** of the LUNA16 dataset.\n",
    "\n",
    "**Note:** Ensure you have downloaded `subset0` and `candidates.csv` into the `data/` directory as described in the `README.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293441f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Add src to path so we can import our modules\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "from dataset import LunaDataset\n",
    "from model import Simple3DCNN\n",
    "from utils import plot_3d_scan, plot_nodule\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31225dc6",
   "metadata": {},
   "source": [
    "## 2. Load and Visualize CT Scan Data\n",
    "\n",
    "We will load the `candidates.csv` file to find the location of potential nodules and then load the corresponding CT scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872530ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load candidates\n",
    "candidates_file = '../data/candidates.csv'\n",
    "if os.path.exists(candidates_file):\n",
    "    candidates = pd.read_csv(candidates_file)\n",
    "    print(f\"Total candidates: {len(candidates)}\")\n",
    "    print(candidates.head())\n",
    "else:\n",
    "    print(\"candidates.csv not found. Please download the dataset.\")\n",
    "\n",
    "# Example: Load one scan (assuming subset0 is present)\n",
    "# You might need to adjust the path to where you extracted subset0\n",
    "subset0_path = '../data/subset0'\n",
    "if os.path.exists(subset0_path):\n",
    "    # Get the first candidate in subset0\n",
    "    # Note: This is a simplified check. In reality, you'd match seriesuid to files in subset0.\n",
    "    # Let's just pick a file from the directory for visualization\n",
    "    mhd_files = [f for f in os.listdir(subset0_path) if f.endswith('.mhd')]\n",
    "    if mhd_files:\n",
    "        example_file = os.path.join(subset0_path, mhd_files[0])\n",
    "        print(f\"Loading {example_file}...\")\n",
    "        \n",
    "        itk_image = sitk.ReadImage(example_file)\n",
    "        scan_array = sitk.GetArrayFromImage(itk_image) # (Z, Y, X)\n",
    "        \n",
    "        print(f\"Scan shape: {scan_array.shape}\")\n",
    "        print(f\"Origin: {itk_image.GetOrigin()}\")\n",
    "        print(f\"Spacing: {itk_image.GetSpacing()}\")\n",
    "        \n",
    "        # Visualize middle slice\n",
    "        plot_3d_scan(scan_array)\n",
    "    else:\n",
    "        print(\"No .mhd files found in subset0.\")\n",
    "else:\n",
    "    print(\"subset0 directory not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec2c8ce",
   "metadata": {},
   "source": [
    "## 3. Preprocess Volumes (Normalization and Patch Extraction)\n",
    "\n",
    "We need to extract 3D patches around the candidates and normalize the pixel intensities (Hounsfield Units). The `LunaDataset` class handles this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec374ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Dataset\n",
    "# Note: This will fail if data is not present.\n",
    "if os.path.exists(subset0_path) and os.path.exists(candidates_file):\n",
    "    dataset = LunaDataset(\n",
    "        root_dir=subset0_path,\n",
    "        candidates_file=candidates_file,\n",
    "        patch_size=(64, 64, 64)\n",
    "    )\n",
    "    \n",
    "    # Get a sample\n",
    "    # We need to find an index that corresponds to a file in subset0\n",
    "    # Since our dataset class currently iterates all candidates, we might hit a file not in subset0.\n",
    "    # For demonstration, we'll just try to find one that works or mock it.\n",
    "    \n",
    "    print(\"Attempting to load a sample patch...\")\n",
    "    try:\n",
    "        # In a real scenario, you'd filter candidates by subset.\n",
    "        # Here we just try the first few until we find one in our subset folder.\n",
    "        for i in range(100):\n",
    "            try:\n",
    "                patch, label = dataset[i]\n",
    "                print(f\"Loaded patch index {i}\")\n",
    "                print(f\"Patch shape: {patch.shape}\")\n",
    "                print(f\"Label: {label}\")\n",
    "                \n",
    "                # Visualize the middle slice of the patch\n",
    "                plt.imshow(patch[0, 32, :, :], cmap='gray')\n",
    "                plt.title(f\"Patch Middle Slice (Label: {label})\")\n",
    "                plt.show()\n",
    "                break\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading patch: {e}\")\n",
    "else:\n",
    "    print(\"Data not available for preprocessing demonstration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c44c84",
   "metadata": {},
   "source": [
    "## 4. Data Augmentation for 3D Images\n",
    "\n",
    "Data augmentation is crucial to prevent overfitting. Common techniques for 3D medical images include:\n",
    "*   Random rotations (axial, coronal, sagittal)\n",
    "*   Random flipping\n",
    "*   Elastic deformations\n",
    "*   Adding noise\n",
    "\n",
    "*Note: The current `LunaDataset` implementation does not include augmentation, but it can be added in the `__getitem__` method.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89911977",
   "metadata": {},
   "source": [
    "## 5. Build the 3D CNN Architecture\n",
    "\n",
    "We use a simple 3D CNN with 4 convolutional blocks, each followed by max pooling. The final layers are fully connected for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1df1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Simple3DCNN()\n",
    "print(model)\n",
    "\n",
    "# Test with a dummy input\n",
    "dummy_input = torch.randn(1, 1, 64, 64, 64)\n",
    "output = model(dummy_input)\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Output value: {output.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d6d9e1",
   "metadata": {},
   "source": [
    "## 6. Compile and Train the Model\n",
    "\n",
    "We use Binary Cross Entropy Loss and the Adam optimizer. The training loop is defined in `src/train.py`.\n",
    "\n",
    "To run the training, you can execute the script from the terminal:\n",
    "```bash\n",
    "python src/train.py\n",
    "```\n",
    "Or run the `train` function directly here (ensure config is correct)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dfbf41",
   "metadata": {},
   "source": [
    "## 7. Evaluate Model Performance\n",
    "\n",
    "After training, we evaluate the model on a held-out test set (e.g., a different subset of LUNA16). We calculate metrics like Accuracy, Sensitivity, and Specificity.\n",
    "\n",
    "*Note: Since we haven't trained a model yet, this section is a placeholder.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caa01a5",
   "metadata": {},
   "source": [
    "## 8. Visualize Prediction Results\n",
    "\n",
    "We can visualize the model's predictions on new data.\n",
    "\n",
    "```python\n",
    "# Example inference code\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # patch = ... load a patch ...\n",
    "    # output = model(patch)\n",
    "    # print(f\"Prediction: {output.item()}\")\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dab0ed3",
   "metadata": {},
   "source": [
    "## 9. Explainability with Grad-CAM\n",
    "\n",
    "We can use Gradient-weighted Class Activation Mapping (Grad-CAM) to visualize which parts of the 3D scan the model is focusing on to make its prediction.\n",
    "\n",
    "This is crucial for medical applications to verify that the model is looking at the nodule and not artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c127c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradcam import GradCAM\n",
    "from dataset import ProcessedLunaDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load a sample from processed data\n",
    "processed_dir = '../data/processed'\n",
    "if os.path.exists(processed_dir):\n",
    "    dataset = ProcessedLunaDataset(processed_dir=processed_dir, augment=False)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    # Load Model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = Simple3DCNN().to(device)\n",
    "    model_path = '../model_epoch_5.pth' # Adjust path if needed\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.eval()\n",
    "        \n",
    "        # Initialize Grad-CAM\n",
    "        gradcam = GradCAM(model, target_layer_name='conv4')\n",
    "        \n",
    "        # Find a positive sample to visualize\n",
    "        for inputs, labels in dataloader:\n",
    "            if labels.item() == 1: # Look for a nodule\n",
    "                inputs = inputs.to(device)\n",
    "                \n",
    "                # Generate CAM\n",
    "                cams = gradcam.generate_cam(inputs, target_class=1)\n",
    "                \n",
    "                patch = inputs.cpu().numpy()[0, 0]\n",
    "                cam = cams[0]\n",
    "                \n",
    "                # Plot Middle Slice\n",
    "                z = patch.shape[0] // 2\n",
    "                \n",
    "                fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                axes[0].imshow(patch[z], cmap='gray')\n",
    "                axes[0].set_title(f\"Original (Label: {int(labels.item())})\")\n",
    "                \n",
    "                axes[1].imshow(cam[z], cmap='jet')\n",
    "                axes[1].set_title(\"Grad-CAM Heatmap\")\n",
    "                \n",
    "                axes[2].imshow(patch[z], cmap='gray')\n",
    "                axes[2].imshow(cam[z], cmap='jet', alpha=0.5)\n",
    "                axes[2].set_title(\"Overlay\")\n",
    "                \n",
    "                plt.show()\n",
    "                break\n",
    "        \n",
    "        gradcam.close()\n",
    "    else:\n",
    "        print(\"Model checkpoint not found. Train the model first.\")\n",
    "else:\n",
    "    print(\"Processed data not found. Run preprocessing first.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
